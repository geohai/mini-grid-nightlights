# Callaway & Sant'Anna Difference in Difference Analysis for a Staggered Treatment

This notebook uses the Callaway & Sant'Anna (2020) Difference in Difference analysis for a staggered treatment. 
The original paper can be found [here](https://www.sciencedirect.com/science/article/pii/S0304407620300253).
An online tutorial can be found [here](https://tilburgsciencehub.com/topics/analyze/causal-inference/did/staggered-did/).

## Load Packages
```{r}
library(tidyverse)
library(did)
library(lubridate)
library(sf)
```

## Combine the Dark and Grid SFs
```{r}
# read in dark_sf
dark_sf <- st_read("data/dark_sl/sl_dark.geojson")
grid_sf <- st_read("data/sl/sl_sites_nighttime.geojson")

glimpse(dark_sf)
glimpse(grid_sf)

# create a type column in grid_sf
grid_sf$type <- "mini-grid"
# make type = "control" for all control sites
grid_sf$type[grid_sf$site_type == "Control"] <- "control"

# drop site_type
grid_sf <- grid_sf %>%
    select(-site_type)
# add a date_commissioned column to dark_sf of "2013-12-01"
dark_sf$date_commissioned <- as.Date("2013-12-01")

# add in a site_name to dark sf of "type" + nrow
dark_sf$site_name <- paste0(dark_sf$type, "_", 1:nrow(dark_sf))

# rename Map to "landcover" and convert to factor
dark_sf <- dark_sf %>%
    rename(landcover = Map)

# combine the sfs
sl_sf <- bind_rows(dark_sf, grid_sf)
rm(dark_sf, grid_sf)

# add in an integer id, unique for each row
sl_sf$id <- 1:nrow(sl_sf)

# export to geojson
st_write(sl_sf, "data/dark_sl/sl_all.geojson")
```

## Convert Data Types
```{r}
# read in the geojson
sl_sf <- st_read("data/dark_sl/sl_all.geojson")

# convert site_name to factor
sl_sf$site_name <- as.factor(sl_sf$site_name)
sl_sf$type <- as.factor(sl_sf$type)
sl_sf$landcover <- as.factor(sl_sf$landcover)
sl_sf$id <- as.factor(sl_sf$id)
glimpse(sl_sf)

# export to RDS
saveRDS(sl_sf, "data/dark_sl/all_sf.rds")
```

## Melt the DF
```{r}
# read in the RDS
sl_sf <- readRDS("data/dark_sl/all_sf.rds")

# convert to df
sl_df <- st_drop_geometry(sl_sf)
rm(sl_sf)

# export the df as RDS
write_rds(sl_df, "data/dark_sl/all_df.rds")

# melt the df
sl_df_melt <- sl_df %>%
    pivot_longer(cols = c(-id, -landcover, -site_name, -type, -date_commissioned), names_to = "image_date", values_to = "image_value")
rm(sl_df)

# change name to df
df <- sl_df_melt
rm(sl_df_melt)

# remove X add the beginning of the image_date column values
df <- df %>%
    mutate(image_date = str_remove(image_date, "X"))

# add dashes to the image_date column instead of 20140101 to 2014-01-01
df <- df %>%
    mutate(image_date = str_replace(image_date, "(\\d{4})(\\d{2})(\\d{2})", "\\1-\\2-\\3"))

# convert image_date to date
df$image_date <- as.Date(df$image_date)

# export the melted df to csv and RDS
write_rds(df, "data/dark_sl/all_df_melt.rds")
```

## Visualize Melted DF Before Cleaning
```{r}
# read in RDS
df <- read_rds("data/dark_sl/all_df_melt.rds")
glimpse(df)

# visualize before cleaning
df %>%
    ggplot(aes(x = image_date, y = image_value, color = id)) +
    geom_line() +
    labs(title = "Image Values Over Time Before Cleaning", x = "Image Date", y = "Image Value") +
    theme_bw() + 
    # hide legend
    theme(legend.position = "none")

# with geom_smooth
df %>%
    filter(type != "built") %>%
    ggplot(aes(x = image_date, y = image_value, color = type)) +
    geom_smooth() +
    labs(title = "Image Values Over Time Before Cleaning", x = "Image Date", y = "Image Value") +
    theme_bw()

# histogram of image values
df %>%
    ggplot(aes(x = image_value)) +
    geom_histogram(binwidth = 0.1) +
    labs(title = "Histogram of Image Values Before Cleaning", x = "Image Value", y = "Count") +
    theme_bw()
```


## Look at Individual Mini-Grid and Control Sites
```{r}
# read in the data
df <- readRDS("data/dark_sl/all_df_for_csdind.rds")

# keep just mini-grid and control sites
df <- df %>%
    filter(type == "mini-grid" | type == "control")

# create a line plot of image_value over time for each site
df %>%
    ggplot(aes(x = time_period, y = image_value, color = id)) +
    geom_line() +
    facet_wrap(~type) +
    labs(title = "Image Values Over Time for Mini-Grid and Control Sites", x = "Time Period", y = "Image Value") +
    # hide the legend
    theme(legend.position = "none") +
    theme_bw()

# one control site is way higher than the rest. It's a railyard. Eliminate it from the analysis. 
```

## Eliminate Bad Sites
```{r}
# read in the RDS
df <- read_rds("data/dark_sl/all_df_melt.rds")
    

# look at the mean image value for each site
site_medians <- df %>%
    # filter(type == "mini-grid" | type == "control") %>%
    group_by(site_name, type, id) %>%
    summarize(
        median_image_value = median(image_value, na.rm = TRUE),
        iqr = IQR(image_value, na.rm = TRUE),
        iqr_median_ratio = iqr / median_image_value,
    ) %>%
    arrange(iqr_median_ratio)

# create histogram of median_iqr_ratio 
site_medians %>%
    ggplot(aes(x = iqr_median_ratio)) +
    geom_histogram(binwidth = 0.01) +
    labs(title = "Histogram of IQR/Median Ratios for Sites", x = "IQR/Median Ratio", y = "Count") +
    theme_bw()

# remove a control site who's median is 8X any other sites
df <- df %>%
    filter(site_name != "Pepel")

# write to rds
write_rds(df, "data/dark_sl/all_df_melt.rds")
```


## Outliers
```{r}
# read in data
df <- readRDS("data/dark_sl/all_df_melt.rds")

# calculate the IQR for image_value by id and add into df
iqr_df <- df %>%
    group_by(id) %>%
    summarize(
        q1 = quantile(image_value, 0.25),
        q3 = quantile(image_value, 0.75),
        iqr = q3 - q1,
        lower = q1 - 1.5 * iqr,
        upper = q3 + 1.5 * iqr
    )
# merge iqr_df with df
df <- left_join(df, iqr_df, by = "id")

# change value image values above the upper limit to the upper limit
df <- df %>%
    mutate(
        image_value = ifelse(image_value > upper, upper, image_value),
        image_value = ifelse(image_value < lower, lower, image_value)
    )

# drop the iqr columns
df <- df %>%
    select(-q1, -q3, -iqr, -lower, -upper)
# rm extra variables
rm(iqr_df)

# revisualize
df %>%
    ggplot(aes(x = image_date, y = image_value, color = id)) +
    geom_line() +
    labs(title = "Image Values Over Time After Cleaning", x = "Image Date", y = "Image Value") +
    theme_bw() + 
    # hide legend
    theme(legend.position = "none")

# with geom_smooth
# set type 
values_by_type_plot <- df %>%
    filter(type != "built") %>%
    ggplot(aes(x = image_date, y = image_value, color = type)) +
    geom_smooth() +
    labs(title = "Nighttime Brightenss Values Over Time by Site Type", x = "Image Date", y = "Nighttime Brightness") +
    theme_bw()
ggsave("figures/dark_sl/values_by_type_plot_hi_res.png", values_by_type_plot, width = 12, height = 6, units = "in", dpi = 900)

df %>%
    ggplot(aes(x = image_value)) +
    geom_histogram(binwidth = 0.1) +
    labs(title = "Histogram of Image Values After Cleaning", x = "Image Value", y = "Count") +
    theme_bw()

# export df to csv and rds
write_rds(df, "data/dark_sl/all_df_melt_clean.rds")
```

## Data Requirements
- There must be a unit-specific identifier variable that does not vary over time. Here that is site_name.
- There must be a time variable. Here that is image_date.
- There must be a group variable, which is usually the period when an individual first becomes treated. For units that are never treated, this variable should be set to 0! Here, we'll group by the date_commissioned variable.
- The variables must be of numeric class.
Note: this analysis can be run without control sites! Worth re-running on the CLUB-ER dataset. 

## Create a Treatment Group Variable
```{r}
# read in data
df <- readRDS("data/dark_sl/all_df_melt.rds")
glimpse(df)

# pull out the earliest date
start_date <- min(df$image_date)
end_date <- max(df$image_date)
start_year <- year(start_date)
end_year <- year(end_date)
start_month <- month(start_date)
end_month <- month(end_date)

# pull out the years and months from the relevant columns
df$month_commissioned <- month(df$date_commissioned)
df$year_commissioned <- year(df$date_commissioned)
df$month_image <- month(df$image_date)
df$year_image <- year(df$image_date)

# convert dates into months since first image
df$group <- (df$year_commissioned - start_year) * 12 + (df$month_commissioned - start_month) + 1 # 1 indexed, 0 for controls
df$time_period <- (df$year_image - start_year) * 12 + (df$month_image - start_month) + 1 # 1 indexed

# remove the extra variables
rm(start_date, end_date, start_year, end_year, start_month, end_month)

# drop the month and year columns
df <- df %>%
    select(-month_commissioned, -year_commissioned, -month_image, -year_image)

# plot histogram of group variable
# set y max to 120
ggplot(df, aes(x = group)) +
    geom_histogram(binwidth = 1) +
    xlim(-5, 120) +
    # scale_y_log10() +
    labs(title = "Histogram of Group Variable", x = "Group", y = "log10(Count)") +
    theme_bw()

# export df to RDS
# View(df)
write_rds(df, "data/dark_sl/all_df_for_csdind.rds")
```

## Run the Analysis
```{r}
# read in the data
df <- readRDS("data/dark_sl/all_df_for_csdind.rds")

# convert id to integer
df$id <- as.integer(df$id)

# keep just certain groups
df <- df %>%
    filter(type == "mini-grid" | type == "control")

# run the model
# https://bcallaway11.github.io/did/reference/att_gt.html
did_control <- att_gt(
    yname = "image_value", # outcome variable
    tname = "time_period", # time variable
    idname = "id", # id variable
    gname = "group", # first treatment period variable
    data = df, # data
    control_group = "nevertreated", # set the comparison group as either "never treated" or "not yet treated"
)

# summary(did_control)

# aggregate the results
did_control_agg <- aggte(
    did_control,
    type = "dynamic", 
    na.rm = TRUE
)

# view the results
summary(did_control_agg)

# plot group-time ATTs
did_control_agg_plt <- ggdid(did_control_agg, xgap = 6) +
    labs(title = "Average Effect of Mini-Grid Construction on Nighttime Brightess for Sierra Leone Mini-Grid Sites", x = "Months Since Commissioning", y = "Change in Brightness") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

print(did_control_agg_plt)

# export the plot to hi-res png
ggsave("figures/dark_sl/did_minigrid_vs_control_v3_hires.png", did_control_agg_plt, width = 12, height = 6, units = "in", dpi = 900)
```

## DiD with Not Yet Treated Sites
```{r}
# read in the data
df <- readRDS("data/dark_sl/all_df_for_csdind.rds")

# convert id to integer
df$id <- as.integer(df$id)

# filter just mini-grid sites
df <- df %>%
    filter(type == "mini-grid")

# run the model
did_notyettreated <- att_gt(
    yname = "image_value", # outcome variable
    tname = "time_period", # time variable
    idname = "id", # id variable
    gname = "group", # first treatment period variable
    data = df, # data
    control_group = "notyettreated", # set the comparison group as either "never treated" or "not yet treated"
)

# aggregate the results
did_notyettreated_agg <- aggte(
    did_notyettreated,
    type = "dynamic", 
    na.rm = TRUE
)

# view the results
summary(did_notyettreated_agg)

# plot group-time ATTs
did_notyettreated_agg_plt <- ggdid(did_notyettreated_agg, xgap = 6) +
    labs(title = "Group-Time ATTs for Sierra Leone Mini-Grid Sites vs Not Yet Treated Sites", x = "Time Period", y = "ATT") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
print(did_notyettreated_agg_plt)

```

## Results

### Mini-Grid vs Control Sites
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.0595        0.0454    -0.1486      0.0295 

### Mini-Grid vs Built Areas
      ATT    Std. Error     [ 95%  Conf. Int.]  
 -0.5227        0.1027    -0.7241     -0.3214 *

### Mini-Grid vs Rural Areas
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.026        0.0431    -0.1104      0.0585 

### Mini-Grid vs Ocean Areas
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.065        0.0451    -0.1534      0.0234 

### Mini-Grids with Not-Yet Treated Sites as Control
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.091        0.0483    -0.1857      0.0037 
 
## ANOVA Test

Assumptipns: 
1. Independence of Observations: The data in each group must be collected independently of the data in the other groups.
2. Normality: The distribution of the residuals should be approximately normal. This can be checked using a Q-Q plot or statistical tests for normality.
3. Homogeneity of Variances: The variance among the groups should be roughly equal. This assumption can be checked with tests such as Levene's test or Bartlett's test.
## Check Assumptions
```{r}
# read in the data
df <- readRDS("data/dark_sl/all_df_for_csdind.rds")

# eliminate the built sites
df <- df %>%
    filter(type != "built")

# check the variances of each type
var_df <- df %>%
    group_by(type) %>%
    summarize(
        var_image_value = var(image_value, na.rm = TRUE),
        mean_image_value = mean(image_value, na.rm = TRUE)
    )
# plot the variances
var_df %>%
    ggplot(aes(x = type, y = var_image_value)) +
    geom_bar(stat = "identity") +
    labs(title = "Variance of Image Values by Type", x = "Type", y = "Variance") +
    theme_bw()

# create a density plot of image values by type, x max is 1
df %>%
    ggplot(aes(x = image_value, fill = type)) +
    # widen the kernel for better visualization
    geom_density(alpha = 0.5, bw = 0.05) +
    xlim(-0.25, 0.75) +
    # add the means as thick vertical lines with the matching colors
    geom_vline(data = var_df, aes(xintercept = mean_image_value, color = type), linetype = "dashed", size = 1) +
    labs(title = "Density Plot of Image Values by Type", x = "Image Value", y = "Density") +
    theme_bw()

# check the normality of the residuals
# eliminate the first two years 2014 and 2015
df <- df %>%
    filter(image_date > "2015-12-31")

# run a Shapiro-Wilk test
df %>%
    group_by(type) %>%
    summarize(
        shapiro_p = shapiro.test(image_value)$p.value,
        shapiro_stat = shapiro.test(image_value)$statistic

    )

```
Shapiro-Wilk Test for Normality Results 
   type      shapiro_p shapiro_stat
  <fct>         <dbl>        <dbl>
1 control    4.16e-54        0.811
2 mini-grid  1.31e-76        0.519
3 ocean      2.82e-17        0.990
4 rural      1.24e-65        0.720

The p-values are all less than 0.05, so we reject the null hypothesis that the data is normally distributed.


If the data were normal....
## Run ANOVA
```{r} 
# run ANOVA for type to see if there are types that are significantly different than mini-grids
anova_res <- aov(image_value ~ type, data = df)
# summary
summary(anova_res)
```
> summary(anova_res)
               Df Sum Sq Mean Sq F value Pr(>F)    
type            3   16.8   5.615   133.8 <2e-16 ***
Residuals   21297  893.7   0.042  

Yes, it looks like they are certainly significantly different.. 

## Post-Hoc Tests
```{r}
# run a Tukey HSD test
tukey_res <- TukeyHSD(anova_res)
# view the results
tukey_res
```
Fit: aov(formula = image_value ~ type, data = df)

$type
                         diff          lwr          upr     p adj
mini-grid-control  0.01925440  0.008728915  0.029779884 0.0000155
ocean-control     -0.05573020 -0.066255683 -0.045204714 0.0000000
rural-control     -0.00950883 -0.020034315  0.001016654 0.0932746
ocean-mini-grid   -0.07498460 -0.084937264 -0.065031932 0.0000000
rural-mini-grid   -0.02876323 -0.038715896 -0.018810564 0.0000000
rural-ocean        0.04622137  0.036268702  0.056174034 0.0000000


But since the data aren't normal....
## Kruskal-Wallis Test
```{r}
# read in the data
df <- readRDS("data/dark_sl/all_df_for_csdind.rds")

# eliminate the built sites
df <- df %>%
    filter(type != "built")

# run a Kruskal-Wallis test
kruskal_res <- kruskal.test(image_value ~ type, data = df)
# view the results
kruskal_res
```
Kruskal-Wallis rank sum test
data:  image_value by type
Kruskal-Wallis chi-squared = 494.22, df = 3, p-value < 2.2e-16

The p-value is less than 0.05, so we reject the null hypothesis that the medians of the groups are equal.

## Post-Hoc Tests
```{r}
library(dunn.test)
# run a Dunn test
dunn_res <- dunn.test(x = df$image_value, g = df$type, method = "bonferroni")
# view the results
dunn_res
```

Kruskal-Wallis rank sum test

data: x and group
Kruskal-Wallis chi-squared = 494.2197, df = 3, p-value = 0


                           Comparison of x by group                            
                                 (Bonferroni)                                  
Col Mean-|
Row Mean |    control   mini-gri      ocean
---------+---------------------------------
mini-gri |  -3.234008
         |    0.0037*
         |
   ocean |   16.49857   20.86827
         |    0.0000*    0.0000*
         |
   rural |   3.598839   7.226107  -13.64217
         |    0.0010*    0.0000*    0.0000*

alpha = 0.05
Reject Ho if p <= alpha/2

The p-values are all less than 0.05, so we reject the null hypothesis that the medians of the groups are equal.
