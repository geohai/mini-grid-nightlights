# Callaway & Sant'Anna Difference in Difference Analysis for a Staggered Treatment

This notebook uses the Callaway & Sant'Anna (2020) Difference in Difference analysis for a staggered treatment. 
The original paper can be found [here](https://www.sciencedirect.com/science/article/pii/S0304407620300253).
An online tutorial can be found [here](https://tilburgsciencehub.com/topics/analyze/causal-inference/did/staggered-did/).

## Load Packages
```{r}
library(tidyverse)
library(did)
library(lubridate)
```

## Read in Data & View Summary Statistics
```{r}
# read in data
df <- read_csv("data/cluber/nighttime_cluber_df_melt.csv")
# View(df)

# check datatypes of each column
glimpse(df)


# count number of unique treatment sites
n_treatment <- df %>%
    count(site_name) %>% nrow()
print(n_treatment)

# pull out the earliest date
start_date <- min(df$image_date)
end_date <- max(df$image_date)
start_year <- year(start_date)
end_year <- year(end_date)
start_month <- month(start_date)
end_month <- month(end_date)

# plot histogram of image values
ggplot(df, aes(x = image_value)) +
    geom_histogram(bins = 100) +
    labs(title = "Histogram of Image Values", x = "Image Value", y = "Count") +
    theme_bw()

# plot the mean brightness by site as a histogram
df %>%
    group_by(site_name) %>%
    summarize(mean_image_value = mean(image_value)) %>%
    ggplot(aes(x = mean_image_value)) +
    geom_histogram(bins = 100) +
    labs(title = "Histogram of Mean Image Values by Site", x = "Mean Image Value", y = "Count") +
    theme_bw()


# examine image_values for each site over time to see if there are any outliers
df %>%
    ggplot(aes(x = image_date, y = image_value, color = site_name)) +
    geom_line() +
    labs(title = "Image Values Over Time", x = "Image Date", y = "Image Value") +
    theme_bw() + # hide legend
    theme(legend.position = "none")
```
688 treatment sites

## Data Cleaning

First remove sites whos means are well above the rest of sites by more than 3 SD. 
```{r}
# read in the site data with outliers
df <- read_csv("data/cluber/nighttime_cluber_df_melt.csv")

# get rid of sites who's means are way above the rest, by greater than 3 sd
# calculate the mean value per site
df <- df %>%
    group_by(site_name) %>%
    mutate(mean_image_value = mean(image_value)) %>%
    ungroup()

# calculate the standard deviation of the means of all sites
sd_site_means <- sd(df$mean_image_value) # 1.84
mean_site_means <- mean(df$mean_image_value) # 0.549

# find the site_names of any sites whos mean is greater than 3 sd above the mean of site means
outliers <- df %>%
    filter(mean_image_value > mean_site_means + 3 * sd_site_means) %>%
    select(site_name) %>%
    distinct()

# remove the outliers
df <- df %>%
    filter(!site_name %in% outliers$site_name)

# revisualize
df %>%
    ggplot(aes(x = image_date, y = image_value, color = site_name)) +
    geom_line() +
    labs(title = "Image Values Over Time", x = "Image Date", y = "Image Value") +
    theme_bw() + # hide legend
    theme(legend.position = "none")

# export df to csv
write_csv(df, "data/cluber/nighttime_cluber_df_melt_low_only.csv")
```

Next, remove outliers from the image values, set to NA
```{r}
# read in the site data with only low sites
df <- read_csv("data/cluber/nighttime_cluber_df_melt_low_only.csv")

# calculate the standard deviation of all sites
sd_all <- sd(df$image_value)
print(sd_all) # 0.743965

# calculate the length of df
n <- nrow(df)
print(n) # 82485

# calculate the number of unique sites
n_sites <- df %>%
    count(site_name) %>% nrow()
print(n_sites) #688

# calculate the max and min value for each site as the mean +/- 3 * sd
df <- df %>%
    mutate(min_image_value = mean_image_value - 3 * sd_all,
           max_image_value = mean_image_value + 3 * sd_all)

# count how many image values are above the max or below the min
n_outliers <- df %>%
    filter(image_value > max_image_value | image_value < min_image_value) %>%
    count()
print(n_outliers) # 302 outliers out of 82485 observations

# replace image_value with max if image_value > max and with min if image_value < min
df <- df %>%
    mutate(image_value = ifelse(image_value > max_image_value, max_image_value, image_value),
           image_value = ifelse(image_value < min_image_value, min_image_value, image_value))

# revisualize
df %>%
    ggplot(aes(x = image_date, y = image_value, color = site_name)) +
    geom_line() +
    labs(title = "Image Values Over Time", x = "Image Date", y = "Image Value") +
    theme_bw() + # hide legend
    theme(legend.position = "none")

# export df to csv
write_csv(df, "data/cluber/nighttime_cluber_df_melt_no_outliers.csv.csv")
```

## Data Requirements
- There must be a unit-specific identifier variable that does not vary over time. Here that is site_name.
- There must be a time variable. Here that is image_date.
- There must be a group variable, which is usually the period when an individual first becomes treated. For units that are never treated, this variable should be set to 0! Here, we'll group by the date_commissioned variable.
- The variables must be of numeric class.
Note: this analysis can be run without control sites! Worth re-running on the CLUB-ER dataset. 

## Create a Treatment Group Variable
```{r}
# read in data
df <- read_csv("data/cluber/nighttime_cluber_df_melt_no_outliers.csv")

# convert id variable to factor to integer
df$site_id <- as.integer(as.factor(df$site_name))

# try the years
df$year_commissioned <- year(df$date_commissioned)
df$year_image <- year(df$image_date)

# extract months
df$month_commissioned <- month(df$date_commissioned)
df$month_image <- month(df$image_date)

# convert dates into months since first image
df$group <- (df$year_commissioned - start_year) * 12 + (df$month_commissioned - start_month)
df$time_period <- (df$year_image - start_year) * 12 + (df$month_image - start_month)

# plot histogram of group variable
# set y max to 120
ggplot(df, aes(x = group)) +
    geom_histogram(bins = 100) +
    xlim(-5, 120) +
    labs(title = "Histogram of Group Variable", x = "Group", y = "Count") +
    theme_bw()

# export df to csv
View(df)
write_csv(df, "data/cluber/nighttime_cluber_values_for_csdind.csv")
```

## Run the Analysis
```{r}
# read in the data
df <- read_csv("data/cluber/nighttime_cluber_values_for_csdind.csv")

# run the model
did_notyettreated <- att_gt(
    yname = "image_value", # outcome variable
    tname = "time_period", # time variable
    idname = "site_id", # id variable
    gname = "group", # first treatment period variable
    data = df, # data
    control_group = "notyettreated", # set the comparison group as either "never treated" or "not yet treated"
    # allow_unbalanced_panel = TRUE # indicate whether or not the function should balance with respect to time and id
)

# aggregate the results
did_notyettreated_agg <- aggte(
    did_notyettreated,
    type = "dynamic", 
    na.rm = TRUE
)

# view the results
summary(did_notyettreated_agg)
# ATT -0.0653, Std. Error 0.0852, 95% CI [-0.2324, 0.1017]

# plot group-time ATTs
did_notyettreated_agg_plt <- ggdid(did_notyettreated_agg) +
    labs(title = "Group-Time ATTs for Not Yet Treated Group", x = "Time Period", y = "ATT") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

print(did_notyettreated_agg_plt)
```
Warnings while running model:
1: In pre_process_did(yname = yname, tname = tname, idname = idname,  :
  Dropped 7 observations while converting to balanced panel.
2: In pre_process_did(yname = yname, tname = tname, idname = idname,  :
  Be aware that there are some small groups in your dataset.
  Check groups: 66,68,70,71,72,76,81,85,87,88,89,90,97,99,100,101,103.
3: In att_gt(yname = "image_value", tname = "time_period", idname = "site_id",  :
  Not returning pre-test Wald statistic due to singular covariance matrix

## Results
Reference: Callaway, Brantly and Pedro H.C. Sant'Anna.  "Difference-in-Differences with Multiple Time Periods." Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. <https://doi.org/10.1016/j.jeconom.2020.12.001>, <https://arxiv.org/abs/1803.09015> 

### Control Group
Overall summary of ATT's based on event-study/dynamic aggregation:  
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.0781        0.0545    -0.1849      0.0288 

### Not Yet Treated Group
Overall summary of ATT's based on event-study/dynamic aggregation:  
     ATT    Std. Error     [ 95%  Conf. Int.] 
 -0.0773        0.0485    -0.1723      0.0178 
