{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Economic Development of Mini-grid Communities \n",
    "\n",
    "## Introduction\n",
    "\n",
    "We'll use Python, Juypter notebooks and GitHub to create our insights. Each week we'll make additions to our code and to investigate this topic. \n",
    "This notebook is going to be a summary of all the data we have on Odyssey and what, how and why we'll use it to generate insights. \n",
    "\n",
    "## CBDA Rules \n",
    "\n",
    "- No creditentials to be stored on GitHub - API Secrets etc. should be stored in the user_config.yml which is ignored by git. \n",
    "- No Developer data is to be stored on GitHub \n",
    "- This data is confidential and any findings should be aggregated and anonymous \n",
    "- Before pushing to GitHub clear all outputs from a juypter notebook \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import elasticsearch # required for connection\n",
    "from elasticsearch import Elasticsearch, client\n",
    "import yaml # for pulling credentials\n",
    "\n",
    "# This is a very useful bit of code and we use it create HTML documents from Jupyter notebooks. \n",
    "# Compile using: \"jupyter nbconvert introduction.ipynb --no-input --to html\" to hide the code inputs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import os\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# We also use a repo_utils to store useful code throughout a project \n",
    "import repo_utils\n",
    "\n",
    "plotly.offline.init_notebook_mode() # Allows publishing of notebook to HTML with plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to Odyssey\n",
    "secrets_file_path = 'odyssey_secrets.yml'\n",
    "with open(secrets_file_path, 'r') as file:\n",
    "    secrets = yaml.safe_load(file)\n",
    "id = secrets['api-id']\n",
    "key = secrets['api-key']\n",
    "\n",
    "host = \"https://f05fc8c52e6b4a99b838818f59bbda80.us-east-1.aws.found.io:9243\"\n",
    "es = Elasticsearch([host], api_key=(id,key),request_timeout=60, max_retries=2, retry_on_timeout=True)\n",
    "es.ping()\n",
    "# str(type(es))\n",
    "# output should be \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code queries our Odyssey database, finding the lastest recording from each of the sites we have data for. \n",
    "# We use this to assess which sites have sent us data lately. \n",
    "query = \"\"\"\n",
    "        SELECT dataKey.project.id, dataKey.project.name,\n",
    "            dataKey.organization.name, metadata.project.country, metadata.project.latitude as latitude, metadata.project.longitude as longitude, metadata.project.status,\n",
    "            metadata.dataProvider, MAX(timestamp) as timestamp, COUNT(DISTINCT dataKey.meter.id) meter_count\n",
    "            FROM daily_meter_summary_logs\n",
    "            GROUP BY dataKey.project.id, dataKey.project.name,\n",
    "            dataKey.organization.name, metadata.project.country, metadata.project.status,\n",
    "            metadata.dataProvider, latitude, longitude\n",
    "        \"\"\"\n",
    "\n",
    "sm_res = repo_utils.query(query, show_progress=True)\n",
    "\n",
    "df = sm_res\n",
    "# Get the most recent timestamp for each project.id. There are repeated values due to different data sources\n",
    "df = df.sort_values(by=[\"site_id_odyssey\", \"timestamp\"], ascending=False)\n",
    "df = df.drop_duplicates(subset=[\"site_id_odyssey\"], keep=\"first\")\n",
    "\n",
    "# Clean up the index\n",
    "df = df.sort_values(by=\"timestamp\", ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "df[\"elapsed_time\"] = (datetime.now(tz=pytz.utc) - df[\"timestamp\"]).dt.days\n",
    "df[\"data_source\"] = df[\"data_source\"].str.replace(\"OES\", \"File upload\", regex=True)\n",
    "# df.drop(columns =[\"site\", \"metadata.project.status\"])\n",
    "\n",
    "df.to_csv(\"./data/daily_meter_summary_logs.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple visualisation to show the range of data freshness that we have and the size of the sites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x = \"timestamp\", y = \"meter_count\", color = \"country\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In answer to your questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We currently have \", len(df), \"sites reporting data on our Odyssey database\") # This gives you an idea of what sites we have and when they were last published.\n",
    "print(\"Of these, there are: \", len(df[df[\"elapsed_time\"] < 365 ]), \" that have sent data to Odyssey in the last year.\")\n",
    "print(\"The latest total meter count is\", sum(df[\"meter_count\"]))\n",
    "print(\"We have co-ordinates for: \", len(df[(df[\"elapsed_time\"] < 365) & (~df[\"latitude\"].isna()) & (~df[\"longitude\"].isna()) ]), \"sites\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of the revenue and consumption data we have. The consumption is in kWh, revenue is in local currency and the recordings are for one day across all of our sites showing individual meter recordings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a sample of daily data we have from a day at random. \n",
    "query = \"\"\"\n",
    "        SELECT timestamp, SUM(meter.energyConsumptionKwh) consump_kwh, SUM(payment.amount) revenue_lc, dataKey.project.name site, dataKey.meter.id meter_id\n",
    "        FROM daily_meter_summary_logs\n",
    "        WHERE timestamp > '2021-05-30' AND timestamp < '2021-06-01' \n",
    "        GROUP BY timestamp, site, meter_id\n",
    "\"\"\"\n",
    "\n",
    "consumption_and_revenue_data = repo_utils.sql_to_df(query, show_progress=True)\n",
    "consumption_and_revenue_data.drop(columns =[\"site\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(consumption_and_revenue_data, x = \"timestamp\", y = \"consump_kwh\", color = \"meter_id\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = \"SOLAR HYBRID MINI-GRID IN RUKUBI DOMA NASARAWA Final Approved\"\n",
    "site_name = repo_utils.parse_to_sql(site_name)\n",
    "\n",
    "query = f\"\"\"\n",
    "        SELECT dataKey.project.id, dataKey.project.name site,\n",
    "            dataKey.organization.name, metadata.project.country, \n",
    "            metadata.project.latitude as latitude, metadata.project.longitude as longitude, metadata.project.status,\n",
    "            metadata.dataProvider, MAX(timestamp) as timestamp, dataKey.meter.id meter_id\n",
    "            \n",
    "            FROM daily_meter_summary_logs\n",
    "            \n",
    "            GROUP BY dataKey.project.id, site, meter_id,\n",
    "            dataKey.organization.name, metadata.project.country, metadata.project.status,\n",
    "            metadata.dataProvider, latitude, longitude\n",
    "        \"\"\"\n",
    "\n",
    "site_data = repo_utils.query(query, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions \n",
    "- Explain the Odyssey eco-system (Good preparation for a handover of this work)\n",
    "- Outline next steps for Isaiah to start investigating this data - Lets try and create just one plot a week to discuss. This will help us build a gallery of our research and makes it easier to create small LinkedIn posts that we can continuously share.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e3bae27b122b90d8f0a0d6ae6d05bfc9988744b22c4f5165a0bfc01dd238698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
